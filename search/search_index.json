{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Home","text":"<p>Bem-vindo(a) \u00e0 p\u00e1gina de Documenta\u00e7\u00e3o para Usu\u00e1rios do LIneA. Este \u00e9 o local central para encontrar guias de usu\u00e1rio e documenta\u00e7\u00e3o sobre todos os servi\u00e7os e ferramentas fornecidos pelo LIneA para a comunidade astron\u00f4mica e p\u00fablico em geral. Aqui voc\u00ea tamb\u00e9m encontrar\u00e1 links para documenta\u00e7\u00e3o externa relevante. </p> <p>O LIneA - Laborat\u00f3rio Interinstitucional de e-Astronomia - \u00e9 um laborat\u00f3rio multiusu\u00e1rio, operado por uma organiza\u00e7\u00e3o sem fins lucrativos (Associa\u00e7\u00e3o LIneA) com apoio financeiro predominantemente proveniente do Minist\u00e9rio da Ci\u00eancia, Tecnologia e Inova\u00e7\u00e3o do Brasil. Nossa miss\u00e3o \u00e9 trabalhar em parceria com o INCT do e-Universo para apoiar a comunidade astron\u00f4mica brasileira com infraestrutura computacional e expertise em an\u00e1lise de big data para fornecer condi\u00e7\u00f5es t\u00e9cnicas para participa\u00e7\u00e3o em grandes levantamentos astron\u00f4micos, como Sloan Digital Sky Survey (SDSS), Dark Energy Survey (DES) e Legacy Survey of Space and Time (LSST). Para saber mais, confira o v\u00eddeo \"Conhe\u00e7a o LIneA\" no nosso canal no YouTube ou navegue no nosso Website institucional. </p> <p>Coment\u00e1rios, d\u00favidas, sugest\u00f5es?</p> <p>Se voc\u00ea encontrar algo faltando nesta documenta\u00e7\u00e3o, fique \u00e0 vontade para abrir um issue  no reposit\u00f3rio de documenta\u00e7\u00e3o do LIneA no GitHub.</p> <p>\u00daltima atualiza\u00e7\u00e3o: 24/06/2024</p>"},{"location":"faq.html","title":"Faq","text":""},{"location":"faq.html#como-criar-par-de-chaves-ssh","title":"Como criar par de chaves SSH","text":"<p>Para acessar nosso ambiente via ssh \u00e9 preciso gerar um par de chaves seguindo os passos abaixos:</p>"},{"location":"faq.html#linux","title":"Linux","text":"<p>a) Para gerar o par de chaves utilize o comando abaixo em seu terminal.</p> <pre><code>ssh-keygen -t rsa -b 4096\n\nGenerating public/private rsa key pair.\nEnter file in which to save the key (/root/.ssh/id_rsa):  [pressione ENTER]\nCreated directory '/root/.ssh'.\nEnter passphrase (empty for no passphrase): [digite uma senha e para confirmar pressione ENTER]\nEnter same passphrase again: [repita a senha e pressione ENTER]\n</code></pre> <p></p> <p>b) Ap\u00f3s voc\u00ea receber a mensagem que a chave foi gerada. Voc\u00ea pode ver os dois arquivos criados listando o conte\u00fado do diret\u00f3rio  <code>ls $HOME/.ssh id_rsa  id_rsa.pub</code></p> <p>c) Ap\u00f3s as chaves geradas enviar a chave .pub para a equipe de TI via email helpdesk@linea.org.br. A equipe de TI do LIneA ir\u00e1 configurar a chave no servidor e retornar com instru\u00e7\u00f5es para login no cluster Apollo. Aguarde o retorno de ok.</p>"},{"location":"faq.html#windows","title":"Windows","text":"<p>Para gerar par de chaves no sistema operacional Windows</p> <p>a) Baixar o aplicativo Putty e instalar.</p> <p>b) Acessar a pasta onde o programa foi instalado (essa instala\u00e7\u00e3o foi no Windows 10)<code>C:\\Program File\\PuTTY</code> (caminho pode ser diferente devido ao sistema operacional), Abra o programa Puttygen.</p> <p></p> <p>c) Clicar em Generate (o tipo de chave mant\u00e9m como RSA).</p> <p></p> <p>OBS : Movimentar o ponteiro do mouse ajuda a gerar a chave mais rapidamente, pois gera bits aleat\u00f3rios.</p> <p></p> <p>d) Par de chaves geradas com sucesso.</p> <ul> <li>Copiar a chave publicar para ser salva no servidor (detalhe na imagem em amarelo);</li> <li>Colocar uma senha na chave p\u00fablica (detalhe na imagem em azul).</li> <li>Ap\u00f3s copiar salve as chaves public e private no computador (detalhe na imagem em vermelho) envie a chave <code>.pub</code> para a equipe de TI via email helpdesk@linea.org.br. A equipe de TI do LIneA ir\u00e1 configurar a chave no servidor. Aguarde o retorno de ok.</li> </ul> <p></p> <p>e) Ap\u00f3s o receber o email de confirma\u00e7\u00e3o que a chave <code>.pub</code> foi cadastrada no servidor de acesso, fazer as configura\u00e7\u00f5es no programa <code>Putty</code>.</p> <ul> <li>Crie um atalho na \u00e1rea de trabalho, abra o <code>PuTTY</code>;</li> <li>Coloque o Hostname login.linea.org.br.</li> </ul> <p></p> <p>f) Ao lado esquerdo ir na op\u00e7\u00e3o <code>SSH &gt; Auth (detalhe em azul) &gt; aperte em Browse (detalhe em amarelo) e escolha a chave a ser usada com exten\u00e7\u00e3o .ppk</code>.</p> <p></p> <p>h) Caso precise utilizar algum t\u00fanel fa\u00e7a a seguinte configura\u00e7\u00e3o.   OBS: os tunnels s\u00e3o configurado conforme o que o usu\u00e1rio vai acessar</p> <ul> <li>Ir na op\u00e7\u00e3o Tunnels (lado esquerdo);</li> <li>Em Source port coloque a porta;</li> <li>Destination &gt; coloque o endere\u00e7o de destino &gt; Add.</li> </ul> <p></p> <p>Volte ao lado esquerdo e v\u00e1 na primeira op\u00e7\u00e3o menu <code>Session (em vermelho) coloque o nome da sessions (em amarelo) e aperte em Save (em azul)</code>, para acessar aperte em <code>Open</code>.</p> <p></p>"},{"location":"glossario.html","title":"Gloss\u00e1rio","text":"<p>Acesse aqui a lista de termos t\u00e9cnicos e acr\u00f4nimos dispon\u00edvel no nosso site.  </p>"},{"location":"monitoramento.html","title":"Monitoramento","text":"<p>TODO</p>"},{"location":"photozserver.html","title":"Photozserver","text":"<p>TODO</p>"},{"location":"politicas.html","title":"Pol\u00edtica de Seguran\u00e7a da Informa\u00e7\u00e3o (PSI)","text":"<p>A Pol\u00edtica de Seguran\u00e7a da Informa\u00e7\u00e3o (PSI) do LIneA define diretrizes estrat\u00e9gicas sobre como a Seguran\u00e7a da Informa\u00e7\u00e3o ser\u00e1 encarada no ambiente da associa\u00e7\u00e3o.</p> <p>Ela foi elaborada pelo Comit\u00ea Gestor de Seguran\u00e7a da Informa\u00e7\u00e3o (CGSI/LIneA) com o apoio do Centro de Atendimento a Incidentes de Seguran\u00e7a da RNP (CAIS/RNP), e cobre diversos aspectos da seguran\u00e7a da informa\u00e7\u00e3o, definindo papeis e responsabilidades tanto para a Associa\u00e7\u00e3o LIneA, quanto para os seus colaboradores e usu\u00e1rios.</p> <p>Para acessar a PSI clique aqui</p>"},{"location":"politicas.html#incidentes-de-seguranca","title":"Incidentes de Seguran\u00e7a","text":"<p>Se voc\u00ea desconfia que ocorreu algum incidente de seguran\u00e7a com sua conta, servi\u00e7o ou aplica\u00e7\u00e3o que voc\u00ea esteja utilizando voc\u00ea deve contatar o LIneA imediatamente em helpdesk@linea.org.br.</p> <p>Recomendamos que salve qualquer evid\u00eancia referente ao incidente (logs, mensagens, screenshots etc) e inclua quantos detalhes for poss\u00edvel no seu email para n\u00f3s.</p>"},{"location":"politicas.html#reconhecimento-de-uso-dos-recursos-computacionais-do-linea","title":"Reconhecimento de uso dos recursos computacionais do LIneA","text":"<p>Por favor, reconhe\u00e7a o LIneA em suas publica\u00e7\u00f5es, por exemplo:</p> <p>Esta pesquisa utilizou recursos computacionais da  Associa\u00e7\u00e3o Laborat\u00f3rio Interinstitucional de e-Astronomia(LIneA) com o apoio financeiro do INCT do e-Universo (Processo n.\u00ba 465376/2014-2).</p>"},{"location":"politicas.html#politica-de-privacidade","title":"Pol\u00edtica de Privacidade","text":"<p>Em breve</p>"},{"location":"politicas.html#politica-de-tratamento-de-dados","title":"Pol\u00edtica de Tratamento de Dados","text":"<p>Em breve </p>"},{"location":"primeiros_passos-old.html","title":"Primeiros passos old","text":""},{"location":"primeiros_passos-old.html#manual-de-boas-vindas","title":"Manual de boas-vindas","text":"<p>O manual \u00e9 um compilado de informa\u00e7\u00f5es importantes sobre o LIneA para aqueles que est\u00e3o conhecendo o laborat\u00f3rio pela primeira vez. Nele podemos encontrar a miss\u00e3o, objetivos, as ferramentas para usu\u00e1rios, os servi\u00e7os de e-ci\u00eancias oferecidos, descri\u00e7\u00e3o dos perfis de usu\u00e1rios, onde buscar ajuda, os representantes das colabora\u00e7\u00f5es cient\u00edficas apoiadas pelo LIneA, maneiras de se comunicar internamente, as redes sociais do LIneA, reuni\u00f5es regulares, gloss\u00e1rio, a pol\u00edtica de seguran\u00e7a da informa\u00e7\u00e3o seguida pelo laborat\u00f3rio, os diferentes tipos de apoio ao usu\u00e1rio disponive\u00eds e, por fim, quem \u00e9 nossa equipe! </p> <p>O manual pode ser acessado por quem desejar entrando nesta p\u00e1gina.</p> <p>Vale dizer que muitas das coisas que est\u00e3o detalhadas no manual de boas vindas voc\u00ea tamb\u00e9m encontra aqui nesta p\u00e1gina de documenta\u00e7\u00e3o, por\u00e9m de forma resumida.</p>"},{"location":"primeiros_passos-old.html#registro-de-usuarios","title":"Registro de usu\u00e1rios","text":""},{"location":"primeiros_passos.html","title":"Primeiros passos","text":"<p>Para ter acesso \u00e0s plataformas e servi\u00e7os disponibilizados pelo LIneA, voc\u00ea precisa efetuar login com uma das duas op\u00e7\u00f5es:</p> <ul> <li>Login via Google - Acess\u00edvel a qualquer pessoa, basta ter um Gmail. Indicado para astr\u00f4nomos amadores, estudantes do Ensino M\u00e9dio, entusiastas da astronomia, etc. </li> <li>Login com credenciais institucionais (feito atrav\u00e9s da CAFe) - Indicado para quem tem v\u00ednculo institucional (graduandos, p\u00f3s-graduandos, pesquisadores, etc), por oferecer mais recursos de processamento e armazenamento. </li> </ul> <p>Aten\u00e7\u00e3o membros de colabora\u00e7\u00f5es cient\u00edficas</p> <p>O login com email institucional \u00e9 obrigat\u00f3rio para acessar servi\u00e7os que s\u00e3o exclusivos para membros das colabora\u00e7\u00f5es (DES, DESI, LSST, SDSS, TON). </p>"},{"location":"primeiros_passos.html#acessando-pela-primeira-vez","title":"Acessando pela primeira vez?","text":"<p>Para ter acesso as plataformas p\u00fablicas do LIneA \u00e9 necess\u00e1rio que seja feito o registro de usu\u00e1rio atrav\u00e9s do preenchimento do formul\u00e1rio neste link.</p>"},{"location":"suporte.html","title":"Suporte","text":"<p>Talvez a sua d\u00favida j\u00e1 tenha resposta, d\u00ea uma olhada na nossa lista de perguntas frequentes antes de abrir um chamado.</p> <p>Para suporte t\u00e9cnico, entre em contato com o nosso Service Desk (suporte via e-mail) ou reserve uma vaga no servi\u00e7o Office Hours (atendimento por v\u00eddeo-chamada) atrav\u00e9s do e-mail helpdesk@linea.org.br. </p> <p>Se voc\u00ea quiser fazer parte da comunidade LIneA e conversar com outros usu\u00e1rios, clique aqui para receber um convite para o Workspace LIneA Users no Slack.</p>"},{"location":"armazenamento/index.html","title":"Armazenamento","text":""},{"location":"armazenamento/index.html#lustrefs-hpc","title":"LustreFS (HPC)","text":"<p>O ambiente do cluster Apollo conta com sistema de arquivos de alta performance Lustre com dois n\u00edveis (tiers) de armazenamento, um em SSD com ~70 TB (T0) e outro em HDD com ~500 TB (T1), ambos conectados a uma rede infiniband EDR de 100 Gb/s. Os dois n\u00edveis de armazenamento est\u00e3o dispon\u00edveis em <code>/lustre/t0</code> e <code>/lustre/t1</code>. </p> <p>Os usu\u00e1rios poder\u00e3o acessar seu diret\u00f3rio de scratch atrav\u00e9s da vari\u00e1vel de ambiente <code>$SCRATCH</code>, ou acessando o diret\u00f3rio localizado em <code>/lustre/t0/scratch/users/&lt;username&gt;</code>. </p>"},{"location":"armazenamento/index.html#boas-praticas","title":"Boas pr\u00e1ticas","text":"<p>Sistemas de arquivos distribu\u00eddos como o Lustre s\u00e3o ideais para ambientes HPC e HTC. Nesses ambientes, a carga de trabalho t\u00edpica consiste em arquivos grandes que precisam ser acessados \u200b\u200ba partir de muitos n\u00f3s de computa\u00e7\u00e3o com largura de banda muito alta e/ou baixa lat\u00eancia. Portanto, esses sistemas de arquivos s\u00e3o muito diferentes dos sistemas de arquivos usados \u200b\u200bem computadores desktop ou servidores isolados. Embora sejam excelentes no manuseio de arquivos grandes, eles tamb\u00e9m apresentam fortes limita\u00e7\u00f5es ao lidar com arquivos pequenos e padr\u00f5es de acesso mais comumente encontrados em ambientes corporativos e de desktop. As opera\u00e7\u00f5es que podem ser extremamente r\u00e1pidas em um disco local de esta\u00e7\u00e3o de trabalho podem ser dolorosamente lentas e caras em um sistema de arquivos Lustre, afetando tanto os usu\u00e1rios que executam essas opera\u00e7\u00f5es quanto, eventualmente, todos os outros usu\u00e1rios. Estas melhores pr\u00e1ticas e recomenda\u00e7\u00f5es t\u00eam como objetivo permitir um uso tranquilo do Lustre, minimizando ou evitando opera\u00e7\u00f5es desnecess\u00e1rias ou muito caras do sistema de arquivos. Evite acessar atributos de arquivos e diret\u00f3rios</p> <p>Acessar informa\u00e7\u00f5es de metadados, como atributos de arquivo (por exemplo, tipo, propriedade, prote\u00e7\u00e3o, tamanho, datas, etc.) no Lustre consome muitos recursos e pode degradar o desempenho do sistema de arquivos, especialmente quando realizado com frequ\u00eancia ou em diret\u00f3rios com grande quantidade de arquivos. Minimize o uso de chamadas de sistema que acessam ou modificam esses atributos, como <code>stat()</code>, <code>statx()</code>, <code>open()</code>, <code>openat()</code>, etc.</p> <p>O mesmo se aplica a comandos como <code>ls -l</code> ou <code>ls --color</code> que fazem uso das chamadas mencionadas acima. Em vez disso, use um simples <code>ls</code> ou <code>ls -l filename</code>.</p> <p>Evite usar comandos que acessam metadados massivamente</p> <p>Evite usar comandos como <code>ls -R</code>, <code>find</code>, <code>locate</code>, <code>du</code>, <code>df</code> e similares. Esses comandos percorrem o sistema de arquivos recursivamente e/ou executam opera\u00e7\u00f5es pesadas de metadados. Eles s\u00e3o muito intensivos no acesso aos metadados do sistema de arquivos e podem degradar gravemente o desempenho geral do sistema de arquivos. Se for absolutamente necess\u00e1rio percorrer o sistema de arquivos recursivamente, use o comando fornecido com o Lustre <code>lfs find</code> em vez de <code>find</code>, por exemplo.</p> <p>Use o comando Lustre lfs</p> <p>Para minimizar o n\u00famero de chamadas Lustre RPC, sempre que poss\u00edvel use os comandos <code>lfs</code> em vez dos comandos fornecidos pelo sistema:</p> <ul> <li><code>lfs df</code> =&gt; em vez de <code>df</code> </li> <li><code>lfs find</code> =&gt; em vez de <code>find</code></li> </ul> <p>Evite usar curingas</p> <p>Expandir os curingas exige muitos recursos. A execu\u00e7\u00e3o de comandos com curingas em um grande n\u00famero de arquivos pode levar muito tempo e afetar gravemente o desempenho do sistema de arquivos. Em vez de usar curingas, crie uma lista dos arquivos de destino e aplique o comando a cada um desses arquivos.</p> <p>Acesso somente leitura</p> <p>Sempre que poss\u00edvel, abra os arquivos como somente leitura usando <code>O_RDONLY</code>, al\u00e9m disso, se voc\u00ea n\u00e3o precisar atualizar o tempo de acesso ao arquivo, abra os arquivos como <code>O_RDONLY | O_NOATIME</code>. Se as informa\u00e7\u00f5es de tempo de acesso forem necess\u00e1rias durante a execu\u00e7\u00e3o de E/S paralela, deixe o processo pai abrir os arquivos como <code>O_RDONLY</code> e todas as outras classifica\u00e7\u00f5es abrirem os mesmos arquivos como <code>O_RDONLY|O_NOATIME</code>.</p> <p>Evite ter um grande n\u00famero de arquivos em um \u00fanico diret\u00f3rio</p> <p>Quando um arquivo \u00e9 acessado, o Lustre bloqueia o diret\u00f3rio pai. Quando muitos arquivos no mesmo diret\u00f3rio devem ser abertos, isso cria conten\u00e7\u00e3o. Gravar milhares de arquivos em um \u00fanico diret\u00f3rio produz uma carga massiva nos servidores de metadados Lustre, geralmente resultando na desativa\u00e7\u00e3o dos sistemas de arquivos. Acessar um \u00fanico diret\u00f3rio contendo milhares de arquivos pode causar grande conten\u00e7\u00e3o de recursos, degradando o desempenho do sistema de arquivos.</p> <p>A alternativa \u00e9 organizar os dados em v\u00e1rios subdiret\u00f3rios e dividir os arquivos entre eles. Uma abordagem comum \u00e9 usar a raiz quadrada do n\u00famero de arquivos, por exemplo, para 90.000 arquivos a raiz quadrada seria 300, portanto devem ser criados 300 diret\u00f3rios contendo 300 arquivos cada.</p> <p>Evite arquivos pequenos</p> <p>Acessar arquivos pequenos no sistema de arquivos Lustre \u00e9 muito ineficiente. O tamanho de arquivo recomendado \u00e9 superior a 1 GB. Reorganize os dados em arquivos grandes ou use formatos de arquivo como HDF5. Alternativamente, se o tamanho total dos arquivos for pequeno, como alguns gigabytes, copie os arquivos pequenos para <code>/tmp</code> ou para um diret\u00f3rio tempor\u00e1rio local para cada n\u00f3 de computa\u00e7\u00e3o no in\u00edcio do trabalho (n\u00e3o se esque\u00e7a de transferir e/ou excluir os arquivos no fim). Essa abordagem pode ser combinada com o uso de ferramentas de arquivamento, como <code>tar</code> e armazenar pequenos arquivos em um ou mais tarballs grandes podem ser mantidos no Lustre de maneira mais eficiente. </p> <p>Ao ler ou gravar arquivos, o Lustre tem um desempenho muito melhor com tamanhos de buffer grandes (&gt;= 1 MB). \u00c9 altamente recomend\u00e1vel agregar pequenas opera\u00e7\u00f5es de leitura e grava\u00e7\u00e3o em opera\u00e7\u00f5es maiores. O buffer coletivo MPI-IO permite E/S agregada.</p> <p>Evite pequenas opera\u00e7\u00f5es repetitivas de arquivos</p> <p>Evite realizar pequenas opera\u00e7\u00f5es de E/S repetitivas, como abrir arquivos frequentemente no modo de acr\u00e9scimo, gravar pequenas quantidades de dados e fechar o arquivo. Em vez disso, abra o arquivo uma vez, execute todas as opera\u00e7\u00f5es de E/S e feche.</p> <p>Evite v\u00e1rios processos abrindo os mesmos arquivos ao mesmo tempo</p> <p>V\u00e1rios processos abrindo os mesmos arquivos ao mesmo tempo podem criar conten\u00e7\u00e3o e erros de abertura de arquivos. Em vez disso, execute a abertura a partir de um \u00fanico processo (pai), ou abra o arquivo somente leitura para evitar bloqueio, ou implemente a abertura com uma abordagem de tentativa e erro com suspens\u00e3o em caso de erro. Evite acessar a mesma regi\u00e3o de arquivo de muitos processos</p> <p>Se v\u00e1rios processos acessarem a mesma regi\u00e3o de arquivo ao mesmo tempo, o gerenciador de bloqueio distribu\u00eddo Lustre refor\u00e7ar\u00e1 a coer\u00eancia para que todos os clientes vejam resultados consistentes. Ter muitos processos tentando acessar a mesma regi\u00e3o de arquivo simultaneamente pode causar degrada\u00e7\u00e3o no desempenho.</p> <p>Neste caso, pode ser prefer\u00edvel: replicar o arquivo, dividir o arquivo, executar as opera\u00e7\u00f5es de E/S a partir de uma \u00fanica classifica\u00e7\u00e3o de processo ou garantir que o acesso simult\u00e2neo n\u00e3o ocorrer\u00e1. Em qualquer caso, \u00e9 recomendado manter a quantidade de opera\u00e7\u00f5es de abertura e bloqueio de arquivos em paralelo t\u00e3o pequena quanto poss\u00edvel para reduzir a conten\u00e7\u00e3o.</p> <p>Se v\u00e1rios processos tentarem anexar ao mesmo arquivo, isso acionar\u00e1 o bloqueio e poder\u00e1 causar grande conten\u00e7\u00e3o. Idealmente, apenas um processo deve anexar cada arquivo.</p> <p>Opera\u00e7\u00f5es de arquivo atrav\u00e9s de processo pai</p> <p>Ao acessar pequenos arquivos compartilhados em uma tarefa paralela, muitas vezes \u00e9 mais eficiente executar todas as opera\u00e7\u00f5es necess\u00e1rias atrav\u00e9s do processo pai e, se necess\u00e1rio, transmitir os dados para outras classifica\u00e7\u00f5es, em vez de acessar os mesmos arquivos de todas as classifica\u00e7\u00f5es. Da mesma forma, se m\u00faltiplas classifica\u00e7\u00f5es de um trabalho paralelo requerem informa\u00e7\u00f5es sobre um determinado arquivo, a abordagem mais eficiente \u00e9 fazer com que o processo pai execute as chamadas necess\u00e1rias (por exemplo <code>stat()</code>, <code>fstat()</code>, etc) e ent\u00e3o transmita as informa\u00e7\u00f5es para as outras classifica\u00e7\u00f5es.</p> <p>Distribui\u00e7\u00e3o de arquivos (striping)</p> <p>No Lustre, arquivos grandes podem ser divididos em segmentos que, por sua vez, podem ser distribu\u00eddos automaticamente por v\u00e1rios dispositivos de armazenamento. A distribui\u00e7\u00e3o de arquivos \u00e9 \u00fatil para E/S paralela em arquivos grandes. Para que isso funcione, o ponto de montagem em quest\u00e3o aponta para v\u00e1rios dispositivos de armazenamento (OSTs). O comando <code>lfs df</code> pode ser usado para verificar se um determinado ponto de montagem aponta para v\u00e1rios OSTs. Para obter informa\u00e7\u00f5es de distribui\u00e7\u00e3o de arquivos para um determinado arquivo, use:</p> <p><code>lfs getstripe filename</code></p> <p>A distribui\u00e7\u00e3o do arquivo pode ser definida usando o comando <code>lfs setstripe</code>. Se o comando for aplicado a um diret\u00f3rio, ele definir\u00e1 as configura\u00e7\u00f5es de distribui\u00e7\u00e3o padr\u00e3o para arquivos criados nesse diret\u00f3rio. Um subdiret\u00f3rio herda todas as configura\u00e7\u00f5es de distribui\u00e7\u00e3o de seu diret\u00f3rio pai. Se o comando for aplicado a um arquivo, ele distribuir\u00e1 esse arquivo pelos OSTs de acordo com as configura\u00e7\u00f5es especificadas.</p> <p><code>lfs setstripe -s 128m -c 8 filename</code> =&gt; divide o arquivo em segmentos de 128 MB e os distribui em 8 OSTs</p> <p>Se um arquivo grande for compartilhado em paralelo por v\u00e1rios processos, com cada processo trabalhando em sua pr\u00f3pria parte do arquivo, ent\u00e3o pode ser \u00fatil dividir o arquivo em um n\u00famero de segmentos igual ao n\u00famero de processos, ou um m\u00faltiplo do n\u00famero de processos.</p> <p>Para obter o m\u00e1ximo desempenho, as solicita\u00e7\u00f5es de E/S devem ser alinhadas \u00e0s faixas, o que significa que os processos que acessam o arquivo devem faz\u00ea-lo em deslocamentos que correspondam aos limites das faixas. Isto minimiza as chances de um processo ter que acessar mais de um segmento (e mais de um OST) para obter os dados necess\u00e1rios.</p> <p>Para arquivos pequenos, a distribui\u00e7\u00e3o (striping) deve ser desabilitada, isso pode ser conseguido definindo uma contagem de distribui\u00e7\u00e3o de 1. O mesmo se aplica se um arquivo grande for acessado por um \u00fanico processo.</p> <p><code>lfs setstripe -s 1m -c 1 meudiretorio/arquivospequenos/</code> </p> <p>Evite instalar software no Lustre </p> <p>Um software geralmente \u00e9 composto de muitos arquivos pequenos e, como mencionado anteriormente, acessar muitos arquivos pequenos no Lustre pode sobrecarregar os servidores de metadados. As compila\u00e7\u00f5es de software em particular podem ser melhor executadas localmente copiando ou descompactando o software para /tmp/$USER/ o para o seu <code>homedir</code>.</p> <p>Al\u00e9m disso, sob alta carga, o acesso de E/S aos sistemas de arquivos Lustre pode ser bloqueado. Se os execut\u00e1veis \u200b\u200bforem armazenados no Lustre e o acesso ao sistema de arquivos falhar, os execut\u00e1veis \u200b\u200bpoder\u00e3o travar. Portanto, sempre que poss\u00edvel, \u00e9 melhor copiar os execut\u00e1veis \u200b\u200bpara o <code>/tmp</code> dos n\u00f3s do cluster.</p>"},{"location":"armazenamento/index.html#quota","title":"Quota","text":"area TB bsoft bhard isoft ihard grace period T0 70 0.4 TB 0.5 TB 10000 11000 7 days"},{"location":"armazenamento/index.html#area-de-scratch","title":"\u00c1rea de scratch","text":"<p>Os arquivos que n\u00e3o foram modificados nos \u00faltimos 60 dias ser\u00e3o automaticamente removidos.</p> <p>Warning</p> <p>Essa \u00e1rea N\u00c3O sofrer\u00e1 backup e tamb\u00e9m N\u00c3O ser\u00e1 enviado aviso de remo\u00e7\u00e3o de arquivos!</p> <p>Warning</p> <p>O script de limpeza \u00e9 executado uma vez por semana sempre nos fins de semana.  </p>"},{"location":"armazenamento/index.html#comandos-uteis","title":"Comandos \u00fateis","text":"<p>a) Como acessar a minha \u00e1rea de scratch?</p> <pre><code>cd $SCRATCH\n</code></pre> <p>b) Como consultar a minha quota dispon\u00edvel?</p> <pre><code>lfs quota -u $USER /lustre/t0\n</code></pre> <p>c) Como consultar os meus arquivos criados h\u00e1 mais de 60 dias? </p> <pre><code>lfs find $SCRATCH --uid $UID -mtime +60 --print\n</code></pre> <p>c) Como consultar os meus arquivos criados h\u00e1 menos de 60 dias? </p> <pre><code>lfs find $SCRATCH --uid $UID -mtime -60 --print\n</code></pre> <p>d) Como listar os OSTs do Lustre?</p> <pre><code>lfs osts /lustre/t0\n</code></pre> <p>e) Como listar os arquivos armazenados h\u00e1 mais de 60 dias em um determinado OST do Lustre?</p> <pre><code>lfs find $SCRATCH -mtime +60 --print --obd t0-OST0002_UUID\n</code></pre> <p>f) Como configurar o striping em diret\u00f3rio de modo a \"quebrar\" os arquivos e distribuir esses \"peda\u00e7os\" em 10 OSTs?</p> <pre><code>lfs setstripe -c 10 $SCRATCH/meus_arquivos_grandes\n</code></pre> <p>g) Como consultar o striping de arquivos/diret\u00f3rios?</p> <pre><code>lfs setstripe -c $SCRATCH/meus_arquivos_grandes\n</code></pre> <p>Tip</p> <p>O Lustre do LIneA foi projetado para trabalhar a 100Gbps, para alcan\u00e7ar o m\u00e1ximo de performance fa\u00e7a uso do striping e sempre com arquivos grandes (+1GB).</p>"},{"location":"armazenamento/index.html#nas-nfs","title":"NAS (NFS)","text":"<p>Os sistemas de armazenamento NAS s\u00e3o utilizados para armazenamento de longo prazo e n\u00e3o est\u00e3o acess\u00edveis atrav\u00e9s dos n\u00f3s de processamento (HPC).</p> <p>Caracter\u00edsticas atuais: </p> Fabricante Modelo Capacidade Instalado em SGI IS5500<sup>[1]</sup> 540TB Dez-2011 SGI IS5600 240TB Jul-2014 <p><sup>[1]</sup> este equipamento foi desativado em Jun/2023 devido a problemas f\u00edsicos.</p>"},{"location":"armazenamento/index.html#home","title":"/home","text":"<p>O diret\u00f3rio <code>home</code> \u00e9 uma \u00e1rea para os usu\u00e1rios armazenarem seus arquivos pessoais e \u00e9 acess\u00edvel atrav\u00e9s dos n\u00f3s de login do cluster e tamb\u00e9m na plataforma jupyter.</p>"},{"location":"armazenamento/index.html#archive","title":"/archive","text":"<p>\u00c1rea de armazenamento de dados brutos de cat\u00e1logos astron\u00f4micos transferidos a partir de outros centros de dados ou produzidos internamente pelas diversas plataformas desenvolvidas pelo LIneA.</p>"},{"location":"armazenamento/index.html#process","title":"/process","text":"<p>\u00c1rea de armazenamento de dados provenientes do processamento de dados do DES realizados pelo Portal do DES.</p>"},{"location":"armazenamento/index.html#quota_1","title":"Quota","text":"area bsoft bhard isoft ihard grace period /home 10 GB 15 GB 1000 1100 7 days"},{"location":"armazenamento/index.html#backup","title":"Backup","text":"\u00e1reas frequ\u00eancia tipo reten\u00e7\u00e3o /home di\u00e1rio incremental 30 dias /home semanal diferencial 30 dias /home mensal completo 90 dias /archive - - - /scratch - - -"},{"location":"armazenamento/index.html#referencias","title":"Refer\u00eancias","text":"<p>Estas melhores pr\u00e1ticas foram compiladas a partir da experi\u00eancia do time do LIneA e das seguintes fontes:</p> <ol> <li>https://www.nas.nasa.gov/hecc/support/kb/lustre-best-practices_226.html</li> <li>https://hpcf.umbc.edu/general-productivity/lustre-best-practices/</li> <li>https://wiki.gsi.de/foswiki/bin/view/Linux/LustreFs</li> <li>https://doc.lustre.org/lustre_manual.pdf</li> </ol>"},{"location":"data/index.html","title":"Acervo de Dados","text":"<p>Warning</p> <p>Em breve.</p>"},{"location":"data/des.html","title":"DES","text":"<p>Warning</p> <p>Esta p\u00e1gina est\u00e1 incompleta, pois est\u00e1 sendo constru\u00edda</p> <p>DES datasets available at LIneA</p> <p>Levantamento inicial de informa\u00e7\u00f5es sobre os datasets do DES dispon\u00edveis no ambiente</p>"},{"location":"data/des.html#archive","title":"Archive","text":""},{"location":"data/des.html#dr2","title":"DR2","text":"<p>There is no DR2 on Archive</p> <ul> <li>Paper or reference: https://ui.adsabs.harvard.edu/abs/2021ApJS..255...20A/abstract</li> <li>Description (paper's abstract): We present the second public data release of the Dark Energy Survey, DES DR2, based on optical/near-infrared imaging by the Dark Energy Camera mounted on the 4 m Blanco telescope at Cerro Tololo Inter-American Observatory in Chile. DES DR2 consists of reduced single-epoch and coadded images, a source catalog derived from coadded images, and associated data products assembled from 6 yr of DES science operations. This release includes data from the DES wide-area survey covering ~5000 deg2 of the southern Galactic cap in five broad photometric bands, grizY. DES DR2 has a median delivered point-spread function FWHM of g = 1.11 arcsec, r = 0.95 arcsec, i = 0.88 arcsec, z = 0.83 arcsec, and Y = 0.90  arcsec, photometric uniformity with a standard deviation of &lt;3 mmag with respect to Gaia DR2 G band, a photometric accuracy of ~11 mmag, and a median internal astrometric precision of ~27 mas. The median coadded catalog depth for a 1.95 arcsec diameter aperture at signal-to-noise ratio = 10 is g = 24.7, r = 24.4, i = 23.8, z = 23.1, and Y = 21.7 mag. DES DR2 includes ~691 million distinct astronomical objects detected in 10,169 coadded image tiles of size 0.534 deg2 produced from 76,217 single-epoch images. After a basic quality selection, benchmark galaxy and stellar samples contain 543 million and 145 million objects, respectively. These data are accessible through several interfaces, including interactive image visualization tools, web-based query clients, image cutout servers, and Jupyter notebooks. DES DR2 constitutes the largest photometric data set to date at the achieved depth and photometric precision.</li> <li>Data access (catalogs and images): easyaccess (internal collaboration) https://desportal.cosmology.illinois.edu/ (internal collaboration) https://des.ncsa.illinois.edu/desaccess/ (public) https://desportal2.cosmology.illinois.edu/ (public) https://datalab.noirlab.edu (public)  </li> </ul>"},{"location":"data/des.html#y6a1_coadd-and-y6a1_gold-and-small-versions","title":"Y6A1_COADD and Y6A1_GOLD (and SMALL versions)","text":"<p><pre><code>tree -L 2 Y6A1_COADD/\nY6A1_COADD/\n\u251c\u2500\u2500 Y6A1_COADD\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 cats\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 depth_maps\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 masks\n\u251c\u2500\u2500 Y6A1_COADD_SMALL\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 healpix\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 masks\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 masks_ -&gt; ../Y6A1_COADD/masks\n\u251c\u2500\u2500 Y6A1_GOLD\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 cats\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 masks\n\u2514\u2500\u2500 Y6A1_GOLD_SMALL\n    \u251c\u2500\u2500 healpix\n    \u2514\u2500\u2500 masks\n\n14 directories, 0 files\n\n\ndu -khs Y6A1_COADD/*/*\n3.6T    Y6A1_COADD/Y6A1_COADD/cats\n2.4G    Y6A1_COADD/Y6A1_COADD/depth_maps\n1.2T    Y6A1_COADD/Y6A1_COADD/masks\n46G     Y6A1_COADD/Y6A1_COADD_SMALL/healpix\n16K     Y6A1_COADD/Y6A1_COADD_SMALL/masks\n0       Y6A1_COADD/Y6A1_COADD_SMALL/masks_\n2.3T    Y6A1_COADD/Y6A1_GOLD/cats\n368K    Y6A1_COADD/Y6A1_GOLD/masks\n3.0G    Y6A1_COADD/Y6A1_GOLD_SMALL/healpix\n4.0K    Y6A1_COADD/Y6A1_GOLD_SMALL/masks\n</code></pre> - Paper (or reference): https://opensource.ncsa.illinois.edu/confluence/pages/viewpage.action?spaceKey=DESDM&amp;title=Y6A1+Release+Notes https://cdcvs.fnal.gov/redmine/projects/des-y6/wiki/Y6_Gold_release - Description: This is not a public catalog, only available for the collaboration. Y6A1 is the first version of DES-Y6 coadd catalog and image, covering all five bands. Y6A1_COADD here is the table Y6A1_COADD_OBJECT_SUMMARY available for the collaboration (also available on easyaccess), and the catalog here is the full catalog for Y6A1 coadd, with 186 columns and 691498505 objects. The catalog is available into two sets: balanced and healpix with only nside 32 available. There is a version of Y6A1_GOLD catalog, which is a catalog based on Y6A1_COADD, but with a few measurements added. The catalog here has 125 columns of the version Y6_GOLD_1_1 (in easyaccess the versions available are Y6_GOLD_1_1, Y6_GOLD_2_0, and Y6_GOLD_2_1), with 334 columns. The catalog Y6_GOLD_1_1 in easyaccess has 690153156 objects. The catalog is available into two sets: balanced and healpix with only nside 32 available. There is a minimal documentation about the depth maps (where they came from, etc). The masks are the complete list of files (*.pol, *.area, *.count, *.fits, *.maglims, *.red, *.time, *.weight) needed to run the systematic maps. Files are organized per tile and band (101689 tiles and five bands). - Data access (catalogs and images): easyaccess (internal collaboration)  </p>"},{"location":"data/des.html#y6a2_coadd-y6a2_gold-y6a2_sof-and-small-versions","title":"Y6A2_COADD, Y6A2_GOLD, Y6A2_SOF (and SMALL versions)","text":"<p><pre><code>tree -L 2 Y6A2_COADD/\n\nY6A2_COADD/ \n\u251c\u2500\u2500 masks   \n\u251c\u2500\u2500 Y6A2_COADD  \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 cats    \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 cats_y6a2   \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 fits    \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 healpix \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 maps    \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 masks   \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 pngs    \n\u2502\u00a0\u00a0 \u2514\u2500\u2500 stilts_converter_Y6A2-coadd_to_Y6A2-small.sh    \n\u251c\u2500\u2500 Y6A2_COADD_SMALL    \n\u2502\u00a0\u00a0 \u2514\u2500\u2500 healpix \n\u251c\u2500\u2500 Y6A2_GOLD   \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 cats    \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 install \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 Y6A2_GOLD_LIMIT.27000000_OFFSET.0.fits  \n\u2502\u00a0\u00a0 \u2514\u2500\u2500 Y6_Gold_2_0.csv \n\u251c\u2500\u2500 Y6A2_GOLD_SMALL \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 cats    \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 healpix \n\u2502\u00a0\u00a0 \u2514\u2500\u2500 install \n\u251c\u2500\u2500 Y6A2_SOF_V2 \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 cats    \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 healpix \n\u2502\u00a0\u00a0 \u251c\u2500\u2500 install \n\u2502\u00a0\u00a0 \u2514\u2500\u2500 Y6A2_SOF_V2.csv \n\u2514\u2500\u2500 Y6_Gold_2_0 \n\u2514\u2500\u2500 Y6_Gold_2_0 \n\ndu -khs Y6A2_COADD/*/*\n274M    Y6A2_COADD/Y6A2_COADD/cats\n0       Y6A2_COADD/Y6A2_COADD/cats_y6a2\n0       Y6A2_COADD/Y6A2_COADD/fits\n898G    Y6A2_COADD/Y6A2_COADD/healpix\n0       Y6A2_COADD/Y6A2_COADD/maps\n9.1G    Y6A2_COADD/Y6A2_COADD/masks\n0       Y6A2_COADD/Y6A2_COADD/pngs\n4.0K    Y6A2_COADD/Y6A2_COADD_SMALL/healpix\n4.0K    Y6A2_COADD/Y6A2_COADD/stilts_converter_Y6A2-coadd_to_Y6A2-small.sh\n1.7T    Y6A2_COADD/Y6A2_GOLD/cats\n36K     Y6A2_COADD/Y6A2_GOLD/install\n0       Y6A2_COADD/Y6A2_GOLD_SMALL/cats\n3.2G    Y6A2_COADD/Y6A2_GOLD_SMALL/healpix\n196K    Y6A2_COADD/Y6A2_GOLD_SMALL/install\n15G     Y6A2_COADD/Y6A2_GOLD/Y6A2_GOLD_LIMIT.27000000_OFFSET.0.fits\n132K    Y6A2_COADD/Y6A2_GOLD/Y6_Gold_2_0.csv\n904G    Y6A2_COADD/Y6A2_SOF_V2/cats\n0       Y6A2_COADD/Y6A2_SOF_V2/healpix\n14M     Y6A2_COADD/Y6A2_SOF_V2/install\n132K    Y6A2_COADD/Y6A2_SOF_V2/Y6A2_SOF_V2.csv\n0       Y6A2_COADD/Y6_Gold_2_0/Y6_Gold_2_0\n</code></pre> - Paper (or reference): https://opensource.ncsa.illinois.edu/confluence/pages/viewpage.action?spaceKey=DESDM&amp;title=Y6A1+Release+Notes - Description: This is not a public catalog, only available for the collaboration. Y6A2 is the reprocessing of only 73 tiles after detect an issue in align DECam images (see the Y6A1 description for reference). See the list of tiles in https://desar2.cosmology.illinois.edu/DESFiles/desarchive/OPS/multiepoch/Y6A2/r5137/. Files in Y6A2_COADD/Y6A2_COADD/healpix/32/.fits here is the table Y6A2_COADD_OBJECT_SUMMARY available for the collaboration, with 186 columns and 691483608 objects. The catalog is available into two sets: balanced and healpix with only nside 32 available. The masks are the set list of files (.pol, *.area, *.count, *.fits, *.maglims, *.red, *.time, *.weight) needed to run the systematic maps for only the tiles that changed in Y6A1 to Y6A2. Y6A2_GOLD is the catalog Y6_GOLD_2_0 version available on easyaccess. The files are split by tile in folder Y6A2_GOLD/cats. The files copied here have the same amount of 333 columns and 691483608 objects.</p> <ul> <li>Data access (catalogs and images): easyaccess (internal collaboration)  </li> </ul> <p>T1</p> <pre><code>tree -L 2 .\n.\n\u251c\u2500\u2500 desar2.cosmology.illinois.edu\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 DESFiles\n\u251c\u2500\u2500 dr2\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 fits\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 ptifs\n\u251c\u2500\u2500 images\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 y6a1_hips\n\u251c\u2500\u2500 process\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 production\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 testing\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 testnagios\n\u251c\u2500\u2500 Y6A2_COADD\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 Y6A2_GOLD\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 Y6A2_GOLD_SMALL\n\u251c\u2500\u2500 y6a2_gold\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 cats\n\u251c\u2500\u2500 Y6A2_GOLD\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 cats\n\u251c\u2500\u2500 Y6A2_GOLD_FITS\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 BALANCED\n\u2514\u2500\u2500 Y6_SUBSET_HIPS\n    \u251c\u2500\u2500 AladinBeta.jar\n    \u251c\u2500\u2500 Hipsgen-cat.jar\n    \u251c\u2500\u2500 imagens\n    \u2514\u2500\u2500 outputs\n\n23 directories, 2 files\n\nGetting information about datasets volume size\n</code></pre>"},{"location":"data/lsst.html","title":"LSST","text":"<p>Warning</p> <p>Esta p\u00e1gina est\u00e1 incompleta, pois est\u00e1 sendo constru\u00edda</p> <p>LSST datasets available at LIneA</p>"},{"location":"data/lsst.html#archive","title":"Archive","text":"<pre><code>\u251c\u2500\u2500 calexp\n\u251c\u2500\u2500 cosmo_dc2\n\u251c\u2500\u2500 dc2\n\u251c\u2500\u2500 dp0\n\u2514\u2500\u2500 images\n\n5 directories, 0 files\n\ndu -khs *\n17G     calexp\n103G    cosmo_dc2\n5.5T    dc2\n345M    dp0\n36G     images\n</code></pre>"},{"location":"data/lsst.html#t1","title":"T1","text":"<pre><code>tree -L 2 .\n.\n\u251c\u2500\u2500 cosmo_dc2\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 EXTRAGALACTIC\n\u251c\u2500\u2500 dp0\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 lsst_dp0\n\u251c\u2500\u2500 dp0.2\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 log_dp0.txt\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 md5sum\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 objectTable_tract_2897_DC2_2_2i_runs_DP0_2_v23_0_1_PREOPS-905_step3_1_20220317T233937Z.parq\n|   \u251c\u2500\u2500 [...] 157 arquivos .parq ocultados\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 objectTable_tract_5074_DC2_2_2i_runs_DP0_2_v23_0_1_PREOPS-905_step3_31_20220314T212509Z.parq\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 objectTable_tract.txt\n\u251c\u2500\u2500 dp0_skinny\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 DP0\n\u251c\u2500\u2500 dr1\n\u251c\u2500\u2500 dr2\n\u251c\u2500\u2500 gawa_project\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 adriano.pieres\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 input_data\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 outputs\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 raslan.oliveira\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 singulani\n\u251c\u2500\u2500 tmp\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 henrique.almeida\n\u2514\u2500\u2500 wazp_project\n    \u251c\u2500\u2500 carlos\n    \u251c\u2500\u2500 datasets\n    \u251c\u2500\u2500 tiles_slices\n    \u251c\u2500\u2500 wazp\n    \u251c\u2500\u2500 wazp-errors.txt\n    \u251c\u2500\u2500 wazp.log\n    \u251c\u2500\u2500 wazp-outfile.txt\n    \u251c\u2500\u2500 wazp_sdumont\n    \u2514\u2500\u2500 wazp_tiles\n\n24 directories, 163 files\n\ndu -khs */*\n354G    cosmo_dc2/EXTRAGALACTIC\n12G     dp0.2/log_dp0.txt\n24K     dp0.2/md5sum\n6.6G    dp0.2/objectTable_tract_2897_DC2_2_2i_runs_DP0_2_v23_0_1_PREOPS-905_step3_1_20220317T233937Z.parq\n[...]  157 arquivos .parq ocultados\n5.9G    dp0.2/objectTable_tract_5074_DC2_2_2i_runs_DP0_2_v23_0_1_PREOPS-905_step3_31_20220314T212509Z.parq\n32K     dp0.2/objectTable_tract.txt\n2.5T    dp0/lsst_dp0\n69G     dp0_skinny/DP0\n</code></pre>"},{"location":"exemplos/exemplos.html","title":"Exemplos","text":""},{"location":"exemplos/exemplos.html#icons-and-emojis","title":"icons and emojis","text":"<p>https://squidfunk.github.io/mkdocs-material/reference/icons-emojis/#icons-emojis</p>"},{"location":"exemplos/exemplos.html#quer-adicionar-um-destaque-sem-quebrar-o-fluxo-do-texto-use-admonitions","title":"Quer adicionar um destaque sem quebrar o fluxo do texto? Use admonitions!","text":"<p>Note</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Info</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Success</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Warning</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Danger</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p>"},{"location":"exemplos/exemplos.html#mais-exemplos-de-admonitions","title":"Mais exemplos de admonitions","text":"<p>https://squidfunk.github.io/mkdocs-material/reference/admonitions/#usage</p>"},{"location":"processamento/index.html","title":"Processamento (HPC)","text":""},{"location":"processamento/index.html#jupyterhub","title":"JupyterHub","text":"<p>Para an\u00e1lise explorat\u00f3ria dos dados, o LIneA oferece poder de processamento atrav\u00e9s da plataforma JupyterHub. Saiba mais detalhes clicando aqui. </p>"},{"location":"processamento/index.html#computacao-de-alto-desempenho-hpc","title":"Computa\u00e7\u00e3o de Alto Desempenho (HPC)","text":"<p>O LIneA oferece acesso recursos computacionais de alto desempenho a usu\u00e1rios membros de colabora\u00e7\u00f5es cient\u00edficas e com projetos apoiados pelo laborat\u00f3rio nos seguintes ambientes:</p> <ul> <li>Cluster HPE Apollo 2000 (LIneA)</li> <li>Open OnDemand</li> <li>JupyterLab over HPC</li> <li>Supercomputador Santos Dumont (LNCC) </li> </ul>"},{"location":"processamento/sdu.html","title":"Santos Dumont (LNCC)","text":"<p>O LIneA possui um projeto \"guarda-chuva\" aprovado no LNCC chamado \"Explorando o Universo via big data: do sistema solar \u00e0 energia escura\" (sigla EUBD) que garante o direito \u00e0 utiliza\u00e7\u00e3o de 2 milh\u00f5es de horas de CPU do supercomputador Santos Dumont para apoiar alguns subprojetos que dependem de High-Performance Computing (HPC) nas seguintes \u00e1reas:</p> <ol> <li>Sistema Solar</li> <li>Via-L\u00e1ctea/Volume Local</li> <li>Energia Escura</li> <li>Estruturas de Larga Escala</li> <li>Redshifts Fotom\u00e9tricos (programa de contribui\u00e7\u00f5es in-kind LSST) </li> </ol> <p>Info</p> <p>Caso seu projeto tenha demandas de HPC e ainda n\u00e3o fa\u00e7a parte do escopo do projeto EUBD, entre em contato conosco atrav\u00e9s do e-mail helpdesk@linea.org.br para receber orienta\u00e7\u00f5es. </p>"},{"location":"processamento/sdu.html#registro-de-usuarios-para-o-acesso-ao-super-computador-projeto-eubd","title":"Registro de usu\u00e1rios para o acesso ao Super Computador - Projeto EUBD","text":"<p>Envie um e-mail, seguindo o modelo abaixo para helpdesk@linea.org.br e aguarde o nosso retorno (no m\u00e1ximo em at\u00e9 72hs).:</p> <p>a.) No campo assunto escreva: </p> <pre><code>Acesso ao supercomputador Santos Dumont - Projeto EUBD\n</code></pre> <p>b.) No corpo do email:</p> <pre><code> 1. Seu nome completo:\n 2. Nome da institui\u00e7\u00e3o (acr\u00f4nimo):\n 3. Nome do orientador (se houver): \n 4. E-mail do orientador/supervisor (se houver):\n 5. Justificativa de uso:\n\n     - Escreva em no m\u00e1ximo 5 linhas qual \u00e9 o objetivo e a import\u00e2ncia de\n   uso desses recursos computacionais.\n     - Se poss\u00edvel, informe quantas CPU/horas pretende utilizar e tamb\u00e9m\n       qual o volume de dados de entrada e de sa\u00edda da sua aplica\u00e7\u00e3o.\n     - Utilize KiloBytes(KB), MegaBytes(MB) ou GigaBytes(GB) para\n       representar o volume de seus dados.\n</code></pre>"},{"location":"processamento/sdu.html#acesso-ao-supercomputador","title":"Acesso ao supercomputador","text":"<p>Ap\u00f3s a obten\u00e7\u00e3o das suas credenciais o acesso dever\u00e1 ser feito em duas etapas:</p> <ol> <li>Conectar-se ao servi\u00e7o de VPN do SDumont (Manuais em PDF: MAC, Linux, Windows)</li> <li>Conectar-se, via SSH, ao host login.sdumont.lncc.br (<code>$ ssh &lt;seu.nome.de.usuario&gt;@login.sdumont.lncc.br</code>) </li> </ol> <p>A submiss\u00e3o dos jobs ser\u00e1 feita atrav\u00e9s do gerenciador de recursos e filas Slurm. O manual de utiliza\u00e7\u00e3o do usu\u00e1rio est\u00e1 dispon\u00edvel na p\u00e1gina do Santos Dumont no site do LNCC. </p>"},{"location":"processamento/apollo/index.html","title":"HPE Apollo 2000","text":"<p>O Cluster Apollo possui 28 n\u00f3s computacionais e oferece um total de 1072 cores f\u00edsicos. Seus n\u00f3s s\u00e3o equipados com processadores <code>Intel Xeon Skylake 5120, 14-cores, 2.2GHz</code> (apl01-14) e <code>Intel(R) Xeon(R) Gold 5320 CPU @ 2.20GHz</code> (apl15-26) com o sistema de hyperthreading ativado. O conjunto de m\u00e1quinas prov\u00ea cerca de 80 Tflops de capacidade computacional. </p> <p>Os 28 n\u00f3s computacionais do Cluster Apollo s\u00e3o da fam\u00edlia de servidores HPE ProLiant, sendo 16 do modelo XL170r e 12 do modelo XL220n. Atualmente, o n\u00famero de cores dispon\u00edveis \u00e9 de 2144 devido o hyper-threading estar ativo nos n\u00f3s de computa\u00e7\u00e3o.</p>"},{"location":"processamento/apollo/index.html#caracteristicas-atuais","title":"Caracter\u00edsticas atuais","text":"# Nodes # Cores Total de ram Instalado em 16<sup>[1]</sup> 448 2TB Abr-2019 12 624 3TB Jul-2023 <p><sup>[1]</sup> atualmente 2 n\u00f3s est\u00e3o sendo usados como m\u00e1quinas de servi\u00e7o do cluster.</p> <p>O Cluster Apollo \u00e9 gerenciado pelo Slurm version 18.08.8.</p>"},{"location":"processamento/apollo/index.html#filesystem","title":"Filesystem","text":"<p>O Cluster Apollo conta com um Filesystem Lustre, utilizado como \"Scratch\". O \"Home\" dos usu\u00e1rios (acess\u00edvel apenas no n\u00f3 de login), \u00e9 fornecido atrav\u00e9s de NFS.</p> <p>Essas \u00e1reas de armazenamento devem ser utilizadas da seguinte forma:</p> <p>Scratch : Estrutura montada a partir do diret\u00f3rio /lustre/t0/scratch/users/. Utilizado para armazenar todos os arquivos que ser\u00e3o utilizados durante a execu\u00e7\u00e3o de um job (scripts de submiss\u00e3o, execut\u00e1veis, dados de entrada, dados de sa\u00edda etc). <p>Home : Estrutura montada a partir do diret\u00f3rio /home/. Utilizado para armazenar especialmente os resultados que se queira manter durante toda a vig\u00eancia do projeto. <p>Clique aqui para mais detalhes</p> <p>Aten\u00e7\u00e3o</p> <p>N\u00e3o esque\u00e7a de copiar os arquivos necess\u00e1rios (execut\u00e1vel, bibliotecas, dados de entrada) para dentro da \u00e1rea de SCRATCH, pois a \u00e1rea de HOMEDIR n\u00e3o \u00e9 acess\u00edvel pelos n\u00f3s computacionais.</p>"},{"location":"processamento/apollo/index.html#slurm","title":"Slurm","text":"<p>Slurm \u00e9 um sistema de gerenciamento de cluster e agendamento de tarefas de c\u00f3digo aberto, tolerante a falhas e altamente escalon\u00e1vel para clusters Linux grandes e pequenos. Slurm n\u00e3o requer modifica\u00e7\u00f5es no kernel para sua opera\u00e7\u00e3o e \u00e9 relativamente independente. Como gerenciador de carga de trabalho de cluster, o Slurm tem tr\u00eas fun\u00e7\u00f5es principais: </p> <ul> <li>alocar acesso exclusivo e/ou n\u00e3o exclusivo aos recursos (n\u00f3s de computa\u00e7\u00e3o) aos usu\u00e1rios por um determinado per\u00edodo de tempo para que possam realizar o trabalho. </li> <li>oferecer uma estrutura para iniciar, executar e monitorar o trabalho (normalmente um trabalho paralelo) no conjunto de n\u00f3s alocados.</li> <li>gerenciar a fila de submiss\u00e3o, arbitrando conflitos entre os pedidos de recursos computacionais.</li> </ul>"},{"location":"processamento/apollo/index.html#particoes-disponiveis","title":"Parti\u00e7\u00f5es dispon\u00edveis","text":"<p>O cluster Apollo \u00e9 organizado em diferentes parti\u00e7\u00f5es (subconjunto de m\u00e1quinas) para atender a diferentes necessidades, por exemplo, a garantia da prioridade m\u00e1xima dos usu\u00e1rios do projeto LSST na utiliza\u00e7\u00e3o das m\u00e1quinas dedicadas ao IDAC-Brasil. </p> PARTITION TIMELIMIT NODES NODELIST cpu_dev 30:00 26 apl[01-26] cpu_small 3-00:00:00 26 apl[01-26] cpu 5-00:00:00 26 apl[01-26] cpu_long 31-00:00:0 26 apl[01-26] LSST infinite 12 apl[15-26]"},{"location":"processamento/apollo/index.html#accounts-disponiveis","title":"Accounts dispon\u00edveis","text":"<ul> <li>Workflow \u2013 Interrompe qualquer job que esteja rodando: hpc-photoz (photoz)</li> <li>LSST \u2013 Pr\u00f3ximo da fila: hpc-lsst [somente nas novas apollos apl[15-26]] (lsst)</li> <li>Grupo A - Prioridade Maior: hpc-bpglsst (itteam, bpg-lsst)</li> <li>Grupo B - Prioridade Intermedi\u00e1ria: hpc-collab (des, desi, sdss, tno)</li> <li>Grupo C - Prioridade Menor: hpc-public (linea-members)</li> </ul> <p>As parti\u00e7\u00f5es (cpu_dev, cpu_small, cpu e cpu_long) possuem todas as apollos (apl[01-26]), enquanto a parti\u00e7\u00e3o LSST possui apenas as apl[15-26]. Por\u00e9m, somente o account hpc-lsst poder\u00e1 submeter jobs nessa parti\u00e7\u00e3o (LSST), que possui prioridade maior nesses nodes.</p> <p>Aten\u00e7\u00e3o</p> <p>Como parte do programa de contribui\u00e7\u00e3o in-kind BRA-LIN, o IDAC Brasil possui o compromisso de gerar redshifts fotom\u00e9tricos anualmente para o levantamento LSST, sempre na \u00e9poca que antecede as libera\u00e7\u00f5es oficiais dos dados. Nestes per\u00edodos, o Cluster Apollo ser\u00e1 totalmente ocupado para este prop\u00f3sito por um tempo estimado de algumas horas, mas podendo se estender a alguns dias. Na ocasi\u00e3o, os usu\u00e1rios ser\u00e3o informados com antec\u00eancia sobre a indisponibilidade do cluster por e-mail. Clique aqui para saber mais sobre a produ\u00e7\u00e3o de medidas de redshift e o programa de conrtribui\u00e7\u00e3o in-kind BRA-LIN. </p>"},{"location":"processamento/apollo/index.html#anatomia-de-um-job","title":"Anatomia de um Job","text":"<p>Um Job solicita recursos de computa\u00e7\u00e3o e especifica os aplicativos a serem iniciados nesses recursos, juntamente com quaisquer dados/op\u00e7\u00f5es de entrada e diretivas de sa\u00edda. O usu\u00e1rio envia a tarefa, geralmente na forma de um script de tarefa em lote, ao agendador em lote. O script de tarefa em lote \u00e9 composto por quatro componentes principais:</p> <ul> <li>O int\u00e9rprete usado para executar o script</li> <li>Diretivas \u201c#\u201d que transmitem op\u00e7\u00f5es de envio padr\u00e3o.</li> <li>A configura\u00e7\u00e3o de vari\u00e1veis de ambiente e/ou script (se necess\u00e1rio)</li> <li>Os aplicativos a serem executados junto com seus argumentos e op\u00e7\u00f5es de entrada.</li> </ul> <p>Aqui est\u00e1 um exemplo de um script em lote que solicita 3 n\u00f3s na parti\u00e7\u00e3o \"cpu\" e inicia 36 tarefas do myApp nos 3 n\u00f3s alocados:</p> <pre><code>#!/bin/bash\n#SBATCH -N 3\n#SBATCH -p cpu\n#SBATCH --ntasks 36\n\nsrun myApp\n</code></pre> <p>Quando a tarefa estiver agendada para execu\u00e7\u00e3o, o gerenciador de recursos executar\u00e1 o script da tarefa em lote no primeiro n\u00f3 da aloca\u00e7\u00e3o.</p>"},{"location":"processamento/apollo/index.html#especificando-recursos","title":"Especificando Recursos","text":"<p>O Slurm tem sua pr\u00f3pria sintaxe para solicitar recursos de computa\u00e7\u00e3o. Abaixo est\u00e1 uma tabela de resumo de alguns recursos solicitados com frequ\u00eancia e a sintaxe de Slurm para obt\u00ea-los. Para obter uma lista completa da sintaxe, execute o comando man sbatch.</p> Sintaxe Significado #SBATCH -p partition Define a parti\u00e7\u00e3o em que o job ser\u00e1 executado #SBATCH -J job_name Define o nome do Job #SBATCH -n quantidade Define o n\u00famero total de tarefas da CPU. #SBATCH -N quantidade Define o n\u00famero de n\u00f3s de computa\u00e7\u00e3o solicitados."},{"location":"processamento/apollo/index.html#comandos-basicos-do-slurm","title":"Comandos B\u00e1sicos do Slurm","text":"<p>Para aprender sobre todas as op\u00e7\u00f5es dispon\u00edveis para cada comando, insira man  enquanto estiver conectado ao ambiente do Cluster. Comando Defini\u00e7\u00e3o sbatch Envia scripts de tarefas para a fila de execu\u00e7\u00e3o scancel Cancela um job scontrol Usado para exibir o estado Slurm (v\u00e1rias op\u00e7\u00f5es dispon\u00edveis apenas para root) sinfo Exibir estado de parti\u00e7\u00f5es e n\u00f3s squeue Exibir estado dos jobs salloc Envia um job para execu\u00e7\u00e3o ou inicia um trabalho em tempo real"},{"location":"processamento/apollo/index.html#ambiente-de-execucao","title":"Ambiente de Execu\u00e7\u00e3o","text":"<p>Para cada tipo de trabalho acima, o usu\u00e1rio tem a capacidade de definir o ambiente de execu\u00e7\u00e3o. Isso inclui defini\u00e7\u00f5es de vari\u00e1veis de ambiente, bem como limites de shell (<code>bash ulimit</code> ou <code>csh limit</code>). sbatch e salloc fornecem a op\u00e7\u00e3o <code>--export</code> para transmitir vari\u00e1veis de ambiente espec\u00edficas para o ambiente de execu\u00e7\u00e3o. E tamb\u00e9m tem a op\u00e7\u00e3o <code>--propagate</code> para transmitir limites espec\u00edficos do shell ao ambiente de execu\u00e7\u00e3o.</p>"},{"location":"processamento/apollo/index.html#variaveis-de-ambiente","title":"Vari\u00e1veis de \u200b\u200bambiente","text":"<p>A primeira categoria de vari\u00e1veis de ambiente s\u00e3o aquelas que o Slurm insere no ambiente de execu\u00e7\u00e3o do trabalho. Eles transmitem ao script da tarefa e informa\u00e7\u00f5es do aplicativo, como ID da tarefa <code>(SLURM_JOB_ID)</code> e ID da tarefa <code>(SLURM_PROCID)</code>. Para obter a lista completa, consulte a se\u00e7\u00e3o <code>\"OUTPUT ENVIRONMENT VARIABLES\"</code> nas p\u00e1ginas sbatch, salloc e srun.</p> <p>A pr\u00f3xima categoria de vari\u00e1veis de ambiente s\u00e3o aquelas que o usu\u00e1rio pode definir em seu ambiente para transmitir op\u00e7\u00f5es padr\u00e3o para cada trabalho enviado. Isso inclui op\u00e7\u00f5es como o limite do rel\u00f3gio de parede. Para obter a lista completa, consulte a se\u00e7\u00e3o <code>\"INPUT ENVIRONMENT VARIABLES\"</code> nas p\u00e1ginas sbatch, salloc e srun.</p> <p>Mais Informa\u00e7\u00f5es ?</p> <p>Saiba como utilizar o Cluster Apollo em Como Utilizar o Ambiente. Para maiores informa\u00e7\u00f5es, entre em contato com o Help Desk enviando um email para helpdesk@linea.org.br.</p>"},{"location":"processamento/uso/howtouse-HPC.html","title":"Como Utilizar","text":""},{"location":"processamento/uso/howtouse-HPC.html#como-acessar","title":"Como acessar","text":"<p>O acesso ao nosso cluster pode ser feito, atrav\u00e9s do Open OnDemand ou pelo do Terminal do JupyterLab (K8S). Em ambas op\u00e7\u00f5es, \u00e9 imprescind\u00edvel possuir uma conta v\u00e1lida no ambiente computacional do LIneA. Caso n\u00e3o possua uma conta, entre em contato com o Service Desk por email (helpdesk@linea.org.br) para mais informa\u00e7\u00f5es.</p> <p>Warning</p> <p>Mesmo possuindo uma conta ativa no LIneA, o acesso ao ambiente de processamento HPC n\u00e3o \u00e9 autom\u00e1tico. Para mais informa\u00e7\u00f5es entre em contato com o Service Desk pelo email helpdesk@linea.org.br.</p> <p>Acessando pelo terminal do JupyterLab</p> <p>Na tela inicial do seu Jupyter Notebook, na se\u00e7\u00e3o \"Other\", voc\u00ea encontrar\u00e1 o bot\u00e3o do terminal. Ao clicar nele, voc\u00ea ser\u00e1 redirecionado para um terminal Linux, inicialmente localizado em seu diret\u00f3rio home. Para acessar o Cluster Apollo, basta executar o seguinte comando:   <pre><code>  ssh loginapl01\n</code></pre></p> <p>A m\u00e1quina loginapl \u00e9 onde voc\u00ea poder\u00e1 fazer a aloca\u00e7\u00e3o do n\u00f3 de computa\u00e7\u00e3o para submeter o seu job. </p> <p>Warning</p> <p>Os n\u00f3s de computa\u00e7\u00e3o n\u00e3o possuem acesso ao seu diret\u00f3rio (home) de usu\u00e1rio. Mova ou copie, para seu diret\u00f3rio SCRATCH, todos os arquivos necess\u00e1rios para a submiss\u00e3o do seu job.</p>"},{"location":"processamento/uso/howtouse-HPC.html#como-usar-a-area-de-scratch","title":"Como usar a area de SCRATCH","text":"<p>Seu diret\u00f3rio SCRATCH \u00e9 o local para enviar os arquivos essenciais \u00e0 submiss\u00e3o do seu Job, assim como verificar os resultados ap\u00f3s a execu\u00e7\u00e3o do c\u00f3digo. \u00c9 crucial informar que <code>todos os resultados e arquivos gerados devem ser transferidos de volta para o seu diret\u00f3rio de usu\u00e1rio (home)</code>. Caso contr\u00e1rio, <code>h\u00e1 o risco de perder esses arquivos armazenados no seu SCRATCH</code>.</p> <ul> <li>Para acessar o seu diret\u00f3rio SCRATCH: <pre><code>  ssh $SCRATCH\n</code></pre></li> <li>Para enviar arquivos para seu diret\u00f3rio SCRATCH: <pre><code>  cp &lt;ARQUIVO&gt; $SCRATCH\n</code></pre></li> </ul>"},{"location":"processamento/uso/howtouse-HPC.html#gerenciador-de-pacotes-eups","title":"Gerenciador de pacotes EUPS","text":"<p>O EUPS \u00e9 um gerenciador de pacotes alternativo (e oficial do LSST) que permite carregar vari\u00e1veis de ambiente e incluir o caminho para programas e bibliotecas de forma modular.</p> <ul> <li>Para carregar o EUPS: <pre><code>  . /mnt/eups/linea_eups_setup.sh\n</code></pre></li> <li>Para listar todos os pacotes dispon\u00edveis: <pre><code>  eups list\n</code></pre></li> <li>Para listar um pacotes espec\u00edfico: <pre><code>  eups list | grep &lt;PACOTE&gt;\n</code></pre></li> <li>Para carregar um pacotes na sess\u00e3o atual: <pre><code>  setup &lt;NOME DO PACOTE&gt; &lt;VERS\u00c3O DO PACOTE&gt;\n</code></pre></li> <li>Para remover o pacote carregado: <pre><code>  unsetup &lt;NOME DO PACOTE&gt; &lt;VERS\u00c3O DO PACOTE&gt;\n</code></pre></li> </ul>"},{"location":"processamento/uso/howtouse-HPC.html#como-submeter-um-job","title":"Como Submeter um Job","text":"<p>Um Job solicita recursos de computa\u00e7\u00e3o e especifica os aplicativos a serem iniciados nesses recursos, juntamente com quaisquer dados/op\u00e7\u00f5es de entrada e diretivas de sa\u00edda. O gerenciamento e agendamento das tarefas e recursos do cluster \u00e9 feito atrav\u00e9s do Slurm. Logo, para submeter um Job \u00e9 necess\u00e1rio utilizar um script como abaixo:</p> <p><pre><code>  #!/bin/bash\n  #SBATCH -p PARTITION                       #Name of the Partition to use\n  #SBATCH --nodelist=NODE                    #Name of the Node to be allocated\n  #SBATCH -J simple-job                          #Job name\n  #----------------------------------------------------------------------------#\n\n  ##path to executable code\n  EXEC=/lustre/t0/scratch/users/YOUR.USER/EXECUTABLE.CODE\n\n  srun $EXEC\n</code></pre> Nesse script \u00e9 preciso especificar o nome da fila (Partition) que ser\u00e1 usada, o nome do n\u00f3 que ser\u00e1 alocado para a excecu\u00e7\u00e3o do Job, e o caminho para o c\u00f3digo/programa a ser executado.            .............. Para mais templates de script de submiss\u00e3o de Jobs, clique aqui ..............</p> <ul> <li> <p>Para submeter o Job: <pre><code>  sbatch script-submit-job.sh\n</code></pre> Se o script estiver correto haver\u00e1 uma sa\u00edda que indica o ID do job.</p> </li> <li> <p>Para verificar o andamento e informa\u00e7\u00f5es do Job: <pre><code>  scontrol show job &lt;ID&gt; \n</code></pre></p> </li> <li>Para cancelar o Job: <pre><code>  scancel &lt;ID&gt; \n</code></pre></li> </ul>"},{"location":"processamento/uso/howtouse-HPC.html#comandos-uteis-do-slurm","title":"Comandos \u00fateis do Slurm","text":"<p>Para aprender sobre todas as op\u00e7\u00f5es dispon\u00edveis para cada comando, insira <code>man &lt;comando&gt;</code> enquanto estiver conectado ao ambiente do Cluster.</p> Comando Defini\u00e7\u00e3o sbatch Envia scripts de tarefas para a fila de execu\u00e7\u00e3o squeue Exibir estado dos jobs scontrol Usado para exibir o estado Slurm (v\u00e1rias op\u00e7\u00f5es dispon\u00edveis apenas para root) sinfo Exibir estado de parti\u00e7\u00f5es e n\u00f3s salloc Envia um job para execu\u00e7\u00e3o ou inicia um trabalho em tempo real"},{"location":"processamento/uso/howtouse-HPC.html#videos-tutoriais","title":"V\u00eddeos tutoriais","text":"<ul> <li>How to login</li> <li>How to use EUPS</li> <li>How to access the Scratch</li> <li>How to submit a Job</li> </ul>"},{"location":"processamento/uso/openondemand.html","title":"Open OnDemand","text":"<p>O Open Ondemand \u00e9 uma interface que facilita a utiliza\u00e7\u00e3o do nosso ambiente de HPC constitu\u00eddo pelo Cluster Apollo. Para acessar \u00e9 necess\u00e1rio possuir uma conta v\u00e1lida no LIneA (saiba mais).  O acesso ao Open Ondemand \u00e9 atrav\u00e9s de https://ondemand.linea.org.br/ .</p> <p>Na tela inicial da plataforma, na parte superior, \u00e9 poss\u00edvel visualizar um menu com os seguinte itens:</p> <ul> <li>Files - fornece uma interface para o seu diret\u00f3rio de usu\u00e1rio (Home Directory).</li> <li>Jobs - fornece uma interface para as telas \u201cActive Jobs\u201d e \u201cJob Composer\u201d.</li> <li>Clusters - fornece um acesso para o terminal em um navegador da web.</li> <li>Interactive Apps - fornece acesso ao Jupyter Notebook.</li> </ul>"},{"location":"processamento/uso/openondemand.html#home-directory","title":"Home Directory","text":"<p>O Home Directory possibilita a visualiza\u00e7\u00e3o do diret\u00f3rio de usu\u00e1rio, onde est\u00e3o armazenados seus arquivos, al\u00e9m de exibir uma variedade de bot\u00f5es com diferentes funcionalidades. </p>"},{"location":"processamento/uso/openondemand.html#mudando-de-diretorio","title":"Mudando de Diret\u00f3rio","text":"<p>Clicar no bot\u00e3o Change Directory permite que voc\u00ea mude de diret\u00f3rio dentro da nossa infraestrutura. Para isso, basta escrever no campo Path o destino que deseja ir e apertar em \"ok\".</p>"},{"location":"processamento/uso/openondemand.html#acessando-o-terminal","title":"Acessando o Terminal","text":"<p>Clicar no bot\u00e3o Open Terminal o levar\u00e1 ao terminal linux dentro da m\u00e1quina de login (loginapl01) do Cluster Apollo.  Neste terminal, voc\u00ea se encontra no seu diret\u00f3rio de usu\u00e1rio e tem a capacidade de visualizar seus arquivos. No terminal tamb\u00e9m \u00e9 poss\u00edvel executar todas as opera\u00e7\u00f5es usuais de usu\u00e1rio HPC, como por exemplo, alocar um n\u00f3 de computa\u00e7\u00e3o e verificar a fila Slurm usando comandos.</p>"},{"location":"processamento/uso/openondemand.html#criando-transferindo-e-movendo-arquivos","title":"Criando, Transferindo e Movendo Arquivos","text":"<p>No Open OnDemand a cria\u00e7\u00e3o de novos arquivos e diret\u00f3rios \u00e9 bem simples, basta clicar nos bot\u00f5es \"New File\" e \"New Directory\" e escolher o nome que deseja. A transfer\u00eancia de arquivos \u00e9 igualmente f\u00e1cil, o bot\u00e3o \"Upload\" permite que voc\u00ea tranfira arquivos da sua m\u00e1quina para o seu diret\u00f3rio de usu\u00e1rio em nosso ambiente, bem como o bot\u00e3o \"Download\" possibilita enviar os arquivos que foram selecionados para a sua m\u00e1quina local. </p> <p>Para visualizar, renomear ou editar o novo arquivo criado, clique no \"tr\u00eas pontinhos\" que aparece ao lado direito do arquivo.</p> <p>Para mover ou copiar arquivos \u00e9 preciso seguir os passos: </p> <ol> <li>Selecionar o arquivo que deseja;</li> <li>Clicar no bot\u00e3o \"Copy/Move\";</li> <li>Clicar em \"Change Directory\" e escrever o caminho do diret\u00f3rio para onde deseja copiar ou mover o arquivo;</li> <li>Clicar em \"Copy\" ou \"Move\" na caixa que aparece no canto esquerdo da tela.</li> </ol>"},{"location":"processamento/uso/openondemand.html#jobs","title":"Jobs","text":"<p>Na se\u00e7\u00e3o Jobs do menu inicial, encontram-se as op\u00e7\u00f5es \"Job Composer\" e \"Active Jobs\". A tela \"Job Composer\" facilita o processo de submiss\u00e3o de jobs e em \"Active Jobs\" voc\u00ea pode acompanhar a execu\u00e7\u00e3o do seu Job com detalhes.</p> <p>Para submeter um job \u00e9 necess\u00e1rio utilizar um script de submiss\u00e3o como este descrito abaixo: (saiba mais) </p> <p><pre><code>#!/bin/bash\n#SBATCH -p PARTITION                       #Name of the Partition to use\n#SBATCH --nodelist=NODE                    #Name of the Node to be allocated\n#SBATCH -J simple-job                            #Job name\n#----------------------------------------------------------------------------#\n\n##path to executable code\nEXEC=/lustre/t0/scratch/users/YOUR.USER/ondemand/projects/EXECUTABLE.CODE\n\nsrun $EXEC\n</code></pre>  .......... Para visualizar mais templates de script de submiss\u00e3o de Jobs, clique aqui ..........</p>"},{"location":"processamento/uso/openondemand.html#job-composer","title":"Job Composer","text":"<p>O Open OnDemand facilita todo o processo de submiss\u00e3o de jobs atrav\u00e9s da ferramenta Job Composer. Para isto basta seguir os seguintes passos:</p> <ol> <li>Clicar no bot\u00e3o \"New Job\";</li> <li>Escolher a op\u00e7\u00e3o \"Default Template\";</li> <li>Editar as especifica\u00e7\u00f5es do script de submiss\u00e3o em \"Open Editor\";</li> <li>Clicar em \"Submit\" para que o Job entre em execu\u00e7\u00e3o.</li> </ol> <p>Warning</p> <p>Os n\u00f3s de computa\u00e7\u00e3o do cluster n\u00e3o possuem acesso ao seu diret\u00f3rio de usu\u00e1rio (Home Directory). Mova ou copie, para seu diret\u00f3rio SCRATCH, todos os arquivos necess\u00e1rios para a submiss\u00e3o do seu job. </p>"},{"location":"processamento/uso/openondemand.html#jupyterlab","title":"JupyterLab","text":"<p>Com o Open OnDemand, \u00e9 vi\u00e1vel acessar o Jupyter Notebook em nosso ambiente de HPC. Por meio de \"Interactive Apps\", o Jupyter Notebook iniciar\u00e1 uma sess\u00e3o em um dos n\u00f3s de computa\u00e7\u00e3o do cluster, bastando para isso:</p> <ul> <li>Clicar em \"Jupyter Notebook\";</li> <li>Em seguida preencher os campos \"Account\", \"Partition\" e \"Select node\"; </li> <li>Depois pressionar o bot\u00e3o \"Launch\".  </li> </ul> <p>Depois de iniciar a sess\u00e3o, voc\u00ea poder\u00e1 conectar-se ao Jupyter Lab - \"Connect to Jupyter\". Ao abrir um terminal dentro do Jupyter, \u00e9 poss\u00edvel verificar que voc\u00ea est\u00e1 localizado em um n\u00f3 do Cluster Apollo e tem acesso \u00e0 sua \u00e1rea \"scratch\" no storage de armazenamento Lustre.</p> <p>Tip</p> <p>N\u00f3s possu\u00edmos dois ambientes Jupyter em duas infraestruturas distintas. Um \u00e9 acess\u00edvel em https://jupyter.linea.org.br e \u00e9 executado sobre Kubernetes e o outro \u00e9 este acima que \u00e9 executado interativamente pela plataforma Open OnDemand diretamente nos n\u00f3s de processamento.</p>"},{"location":"processamento/uso/openondemand.html#videos-tutoriais","title":"V\u00eddeos tutoriais","text":"<ul> <li>Usando o Open OnDemand</li> <li>Como submeter um Job</li> <li>Como acessar o Jupyter Notebook </li> </ul>"},{"location":"processamento/uso/templates-jobs.html","title":"Submit Job Scripts - Templates","text":""},{"location":"processamento/uso/templates-jobs.html#simple-job-script","title":"Simple Job Script","text":"<p><pre><code>  #!/bin/bash\n  #SBATCH -p PARTITION                       #Name of the Partition to use\n  #SBATCH --nodelist=NODENAME                #Name of the Node to be allocated\n  #SBATCH -J JOB-NAME                                  #Job name\n  #----------------------------------------------------------------------------#\n\n  ##path to executable code\n  EXEC=/lustre/t0/scratch/users/YOUR.USER/EXECUTABLE.CODE\n\n  srun $EXEC\n</code></pre> Nesse script \u00e9 preciso especificar o nome da fila (Partition) que ser\u00e1 usada, o nome do n\u00f3 que ser\u00e1 alocado para a excecu\u00e7\u00e3o do Job, e o caminho para o c\u00f3digo/programa a ser executado.</p>"},{"location":"processamento/uso/templates-jobs.html#eups-load-script","title":"EUPS Load Script","text":"<pre><code>  #!/bin/bash\n  #SBATCH -p PARTITION                     #Name of the Partition to use\n  #SBATCH --nodelist=NODENAME              #Name of the Node to be allocated\n  #SBATCH -J JOB-NAME              #Job name\n  #----------------------------------------------------------------------------#\n\n  #Carregar o EUPS\n  . /mnt/eups/linea_eups_setup.sh\n\n  #Carregar pacote \n  setup &lt;PACKAGE&gt; &lt;VERSION&gt;\n\n  ##path to executable code\n  EXEC=/lustre/t0/scratch/users/YOUR.USER/EXECUTABLE.CODE\n\n  srun $EXEC\n</code></pre>"},{"location":"processamento/uso/templates-jobs.html#parallel-submit-job-script","title":"Parallel Submit Job Script","text":""},{"location":"processamento/uso/templates-jobs.html#openmp","title":"OpenMP","text":""},{"location":"processamento/uso/templates-jobs.html#mpi","title":"MPI","text":""},{"location":"sci-platforms/index.html","title":"Plataformas Cient\u00edficas","text":""},{"location":"sci-platforms/index.html#linea-science-platform-lsp","title":"LIneA Science Platform (LSP)","text":"<p>O LIneA Science Platform, ou LSP (lsp.linea.org.br), \u00e9 uma plataforma online que agrega um conjunto de servi\u00e7os e ferramentas oferecidas para facilitar o acesso e a an\u00e1lise dos dados astron\u00f4micos hospedados no LIneA. Clique aqui para saber mais sobre o LSP. </p> <p>Durante a opera\u00e7\u00e3o do levantamento LSST, o LSP ser\u00e1 o principal ponto de acesso aos dados para os cientistas da comunidade Brasileira, tanto para os membros do Brazilian Participation Group (BPG), que ter\u00e3o acesso aos dados propriet\u00e1rios a cada data release, e para os demais cientistas, que ter\u00e3o acesso apenas aos dados p\u00fablicos ap\u00f3s o per\u00edodo de embargo estabelecido pelo levantamento. O LSP vai oferecer acesso aos dados hospedados no Brazilian Independent Data Access Center (IDAC), cumprindo papel semelhante ao da plataforma Rubin Science Platform (RSP) no Data Access Center estadunidense. Clique aqui para saber mais sobre o gerenciamento de dados do LSST na p\u00e1gina do Vera C. Rubin Observatory. </p> <p>Nos anos que antecedem a opera\u00e7\u00e3o do LSST, o LSP (que ainda est\u00e1 em fase de desenvolvimento) j\u00e1 disponibiliza acesso a dados que s\u00e3o p\u00fablicos, como por exemplo o segundo data release do levantamento Dark Energy Survey (DES DR2), para que a comunidade possa se preparar e se familiarizar com as diversas ferramentas oferecidas. </p> <p>Para dados embargados, o acesso depende de credenciais espec\u00edficas. Para saber como criar uma conta no LIneA e ter acesso aos dados, leia a se\u00e7\u00e3o Primeiros Passos. </p>"},{"location":"sci-platforms/index.html#servicos-oferecidos","title":"Servi\u00e7os oferecidos:","text":""},{"location":"sci-platforms/index.html#jupyterhub","title":"JupyterHub","text":""},{"location":"sci-platforms/index.html#science-server","title":"Science Server","text":""},{"location":"sci-platforms/index.html#user-query","title":"User Query","text":""},{"location":"sci-platforms/index.html#portais-cientificos","title":"Portais Cient\u00edficos","text":"<p>Os portais cient\u00edficos oferecem ferramentas de processamento e visualiza\u00e7\u00e3o de dados desenvolvidas especificamente para cada projeto e s\u00e3o de uso restrito dos membros de cada colabora\u00e7\u00e3o. </p>"},{"location":"sci-platforms/index.html#des-science-portal","title":"DES Science Portal","text":""},{"location":"sci-platforms/index.html#sso-portal","title":"SSO Portal","text":""},{"location":"sci-platforms/index.html#manga-portal","title":"MaNGA Portal","text":""},{"location":"sci-platforms/des.html","title":"DES Science Portal","text":"<p>O DES Science Portal (des-portal.linea.org.br/) \u00e9 uma plataforma desenvolvida para o projeto Dark Energy Survey. Ele hospeda uma variedade de pipelines destinados a preparar cat\u00e1logos customizados para diferentes aplica\u00e7\u00f5es na astronomia, bem como para realizar uma variedade de an\u00e1lises cient\u00edficas. Os pipelines s\u00e3o agrupados em etapas:</p> <ul> <li> <p>Data Preparation - que inclui a cria\u00e7\u00e3o de mapas de efeitos sistem\u00e1ticos, classifica\u00e7\u00e3o de objetos (estrela/gal\u00e1xia), c\u00e1lculo de redshifts fotom\u00e9tricos e outros valores agregados dependendo da aplica\u00e7\u00e3o. Por exemplo, estimativa de idade, metalicidade ou massa estelar de gal\u00e1xias. </p> </li> <li> <p>Value-added Catalog - combina os dados e resultados obtidos na etapa anterior, seleciona as colunas de interesse e aplica cortes de qualidade e limpeza dos dados, com crit\u00e9rios fortemente dependentes da aplica\u00e7\u00e3o cient\u00edfica para a qual o cat\u00e1logo ser\u00e1 destinado. </p> </li> <li> <p>Science Workflows - agrega diversos pipelines de an\u00e1lise cient\u00edfica. Tem como dados de entrada os cat\u00e1logos criados na etapa anterior. </p> </li> </ul> <p>Um dos principais pontos fortes do DES Science Portal \u00e9 a capacidade de fornecer informa\u00e7\u00f5es completas de todo o hist\u00f3rico de processos executados, permitindo ao usu\u00e1rio rastrear a entrada, a configura\u00e7\u00e3o, a vers\u00e3o dos c\u00f3digos utilizados e os resultados obtidos na forma de um registro do produto com gr\u00e1ficos e tabelas informativas. O portal tamb\u00e9m fornece acesso a uma s\u00e9rie de ferramentas destinadas ao usu\u00e1rio, ao desenvolvedor e ao administrador.</p> <p>Para se aprofundar nos detalhes sobre o DES Science Portal, leia os dois artigos publicados na revista Astronomy and Computing: </p> <ul> <li>Gschwend et al. 2018 - DES science portal: Computing photometric redshifts (doi.org/10.1016/j.ascom.2018.08.008) (arXiv:1708.05643)   </li> <li>Fausti Neto et al. 2018 - DES science portal: Creating science-ready catalogs (doi.org/10.1016/j.ascom.2018.01.002) (arXiv:1708.05642)</li> </ul>"},{"location":"sci-platforms/jupyter.html","title":"JupyterLab (K8S)","text":"<p>O JupyterHub \u00e9 um ambiente de desenvolvimento multiusu\u00e1rio baseado em iPython Notebooks que oferece acesso a recursos computacionais compartilhados em um servidor remoto, sem a necessidade de instala\u00e7\u00e3o e manuten\u00e7\u00e3o por parte dos usu\u00e1rios. Os \u00fanicos pr\u00e9-requisitos para acessar o JupyterHub s\u00e3o: ter uma conta de usu\u00e1rio no LIneA (veja aqui como criar sua conta) e um navegador com acesso \u00e0 Internet. Os chamados Jupyter Notebooks permitem combinar c\u00f3digo interativo, resultados de execu\u00e7\u00e3o, texto explicativo e recursos de multim\u00eddia em um s\u00f3 documento.  </p> <p>Como parte do LIneA Science Platform, o LIneA JupyterHub est\u00e1 integrado \u00e0s demais ferramentas de visualiza\u00e7\u00e3o (Science Server) e acesso a dados (User Query). Desse modo, toda a an\u00e1lise de dados pode ser feita online dentro da plataforma, desde a leitura, visualiza\u00e7\u00e3o, processamento e an\u00e1lise de resultados, sem a necessidade de download dos dados. </p> <p>Ao clicar no card \"JupyterHub\" dentro do LIneA Science Platform, voc\u00ea ser\u00e1 direcionado para a p\u00e1gina de login e em seguida para a p\u00e1gina inicial do JupyterHub que mostrar\u00e1 o seu perfil de usu\u00e1rio. Clique no bot\u00e3o START para iniciar.       </p> <p>A instala\u00e7\u00e3o padr\u00e3o do JupyterHub utiliza a nova interface JupyterLab e \u00e9 baseada na imagem datascience-notebook, estendida com as bibliotecas Astropy e dblinea (a biblioteca que faz a conex\u00e3o com o banco de dados). Isto significa que uma s\u00e9rie de bibliotecas Python de grande popularidade como Numpy e Matplotlib estar\u00e3o automaticamente dispon\u00edveis.</p>"},{"location":"sci-platforms/jupyter.html#apoio-ao-usuario","title":"Apoio ao usu\u00e1rio","text":""},{"location":"sci-platforms/jupyter.html#tutoriais-em-jupyter-notebooks","title":"Tutoriais em Jupyter Notebooks","text":"<p>No reposit\u00f3rio jupyterhub-tutorial voc\u00ea encontrar\u00e1 os tutoriais em formato notebook:</p>"},{"location":"sci-platforms/jupyter.html#1-primeiros-passosipynb","title":"1-primeiros-passos.ipynb","text":"<p>Instru\u00e7\u00f5es gerais de uso da plataforma JupyterLab, dicas e atalhos na escrita de notebooks para diferentes tipos de c\u00e9lulas. </p>"},{"location":"sci-platforms/jupyter.html#2-acesso-a-dadosipynb","title":"2-acesso-a-dados.ipynb","text":"<p>Instru\u00e7\u00f5es para uso da biblioteca dblinea para leitura de dados a partir do banco de dados diretamente de dentro de uma c\u00e9lula no notebook com exemplo de uso (constru\u00e7\u00e3o de um diagrama cor-magnitude simples para uma amostra de estrelas). </p>"},{"location":"sci-platforms/jupyter.html#3-conda-envipynb","title":"3-conda-env.ipynb","text":"<p>Instru\u00e7\u00f5es para cria\u00e7\u00e3o de ambientes no conda para gerenciamento de bibliotecas que sejam persistentes e sobrevivam a destrui\u00e7\u00e3o e recria\u00e7\u00e3o dos containers para que os usu\u00e1rios possam retornar em uma nova sess\u00e3o e encontrar o mesmo ambiente da sess\u00e3o anterior (n\u00e3o dispon\u00edvel para usu\u00e1rios de perfil p\u00fablico bronze).  </p> <p>Para acessar os notebooks, basta abrir um Terminal no JupyterLab clicando no bot\u00e3o \"+\" na barra superior e em seguida no \u00edcone \"Terminal\" da se\u00e7\u00e3o \"Other\" na aba \"Launcher\", e inserir o comando:</p> <pre><code>git clone https://github.com/linea-it/jupyterhub-tutorial.git\n</code></pre>"},{"location":"sci-platforms/manga.html","title":"MaNGA Portal","text":"<p>O portal MaNGA (https://manga.linea.org.br/) foi desenvolvido para atender \u00e0s necessidades dos membros do Brazilian Participation Group do levantamento MaNGA do Sloan Digital Sky Survey. O sistema foi projetado para permitir que a equipe visualize, n\u00e3o apenas os cubos de dados de espectroscopia IFU (Integral Field Units) reduzidos, mas os resultados da an\u00e1lise dos dados mostrando mapas de v\u00e1rias quantidades f\u00edsicas derivadas dos espectros. </p> <p>Para mais informa\u00e7\u00f5es consulte os tutoriais no site do portal MaNGA.</p>"},{"location":"sci-platforms/sci_server.html","title":"Science Server","text":"<p>O LIneA Science Server \u00e9 um servi\u00e7o de visualiza\u00e7\u00e3o de imagens e dados de cat\u00e1logos que foi inicialmente desenvolvido no contexto do levantamento DES, mas continua em desenvolvimento e est\u00e1 recebendo melhorias para operar na era do LSST. O LIneA Science Server ser\u00e1 a principal ferramenta de visualiza\u00e7\u00e3o de dados oferecida pelo IDAC-Brasil. </p>"},{"location":"sci-platforms/sci_server.html#sky-viewer","title":"Sky viewer","text":"<p>Oferece exibi\u00e7\u00e3o panor\u00e2mica das imagens do DES, combinadas para formar uma imagem \u00fanica limitada apenas pelas bordas do footprint, e de mapas em formato HEALPix.  </p>"},{"location":"sci-platforms/sci_server.html#target-viewer","title":"Target viewer","text":"<p>Ferramenta para visualizar e manipular imagens de uma lista de objetos previamente definida (targets). Oferece a possibilidade de rankear imagens, aplicar filtros baseados em propriedades dos objetos e criar mosaicos com m\u00faltiplas imagens. </p>"},{"location":"sci-platforms/sci_server.html#tile-viewer","title":"Tile Viewer","text":"<p>Oferece a visualiza\u00e7\u00e3o das imagens do DES com exibi\u00e7\u00e3o baseada nas Tiles, a unidade de \u00e1rea adotada pelo levantamento. O Tile Viewer foi amplamente utilizado na inspe\u00e7\u00e3o e valida\u00e7\u00e3o dos dados nos per\u00edodos que antecederam os data releases internos e p\u00fablicos.</p>"},{"location":"sci-platforms/sci_server.html#apoio-ao-usuario","title":"Apoio ao usu\u00e1rio","text":""},{"location":"sci-platforms/sci_server.html#tutoriais-em-video","title":"Tutoriais em v\u00eddeo","text":"<p>O site do LIneA Science Server possui uma p\u00e1gina de tutoriais em v\u00eddeos, com narra\u00e7\u00e3o em ingl\u00eas, com exemplos de uso das ferramentas. Acesse os v\u00eddeos em: https://scienceserver.linea.org.br/tutorials</p>"},{"location":"sci-platforms/sci_server.html#minicurso","title":"Minicurso","text":"<p>Como parte das atividades do programa de Inicia\u00e7\u00e3o Cient\u00edfica (IC), em 2022 o LIneA ofereceu uma s\u00e9rie de minicursos para os estudantes e demais interessados com aulas remotas e atividades pr\u00e1ticas propostas. Os v\u00eddeos das aulas est\u00e3o dispon\u00edveis na p\u00e1gina do Minicurso LIneA Science Server no Google Classroom.  </p>"},{"location":"sci-platforms/sso.html","title":"Solar System Portal","text":"<p>O estudo de pequenos corpos no Sistema Solar apresenta desafios consider\u00e1veis, principalmente devido aos seus pequenos tamanhos e vastas dist\u00e2ncias. Um m\u00e9todo para superar esses obst\u00e1culos envolve estudos indiretos atrav\u00e9s de uma t\u00e9cnica conhecida como oculta\u00e7\u00e3o estelar. Historicamente, a predi\u00e7\u00e3o precisa destes eventos se provou ser dif\u00edcil devido \u00e0 falta de mapas estelares suficientemente precisos. No entanto, os avan\u00e7os recentes transformaram esta cen\u00e1rio, permitindo predi\u00e7\u00f5es de oculta\u00e7\u00f5es estelares altamente precisas para corpos do Sistema Solar. A t\u00e9cnica de oculta\u00e7\u00e3o estelar \u00e9 uma ferramenta crucial para estudar estes corpos, especialmente os TNOs, oferecendo informa\u00e7\u00f5es precisas sobre os seus tamanhos e posi\u00e7\u00f5es, bem como sobre o seu entorno, gra\u00e7as a uma das caracter\u00edsticas mais marcante da t\u00e9cnica: a tradu\u00e7\u00e3o de alta resolu\u00e7\u00e3o temporal em alta resolu\u00e7\u00e3o angular. Dado o esperado aumento de dez vezes no volume de dados do Sistema Solar a partir do Legacy Survey of Space and Time (LSST), o Portal do Sistema Solar pretende ser uma solu\u00e7\u00e3o de computa\u00e7\u00e3o de alto desempenho que prev\u00ea, organiza e distribui esses eventos, tornando-os globalmente acess\u00edveis para a comunidade, ao mesmo tempo que alivia a carga computacional.</p> <p>Este portal est\u00e1 divido entre uma interface p\u00fablica e uma inteface destinada a usu\u00e1rios membros. Para acessar todas as predi\u00e7\u00f5es de oculta\u00e7\u00f5es p\u00fablicas acesse o LIneA Occultation Prediction Database e para uso avan\u00e7ado da plataforma consulte a documenta\u00e7\u00e3o.</p> <p>O LIneA Solar System Portal \u00e9 destinado aos membros da colabora\u00e7\u00e3o Transneptunian Occultation Network (TON). Clique aqui para saber mais sobre a TON.  </p>"},{"location":"sci-platforms/user_query.html","title":"User Query","text":"<p> Em breve! (servi\u00e7o em desenvolvimento)  </p> <p>O User Query \u00e9 uma interface amig\u00e1vel para consultas ao banco de dados que vai possibilitar a cria\u00e7\u00e3o de tabelas tempor\u00e1rias com resultados imediatamente dispon\u00edveis para visualiza\u00e7\u00e3o no Target Viewer. </p> <p>Uma vers\u00e3o preliminar do User Query est\u00e1 dispon\u00edvel dentro do site \"espelho\" do LIneA Science Server que est\u00e1 hospedado no NCSA, acess\u00edvel apenas para membros da colabora\u00e7\u00e3o DES. Uma nova implementa\u00e7\u00e3o est\u00e1 sendo preparada com base no software Daiquiri e estar\u00e1 dispon\u00edvel em breve para os todos os usu\u00e1rios do LIneA Science Platform. </p>"}]}